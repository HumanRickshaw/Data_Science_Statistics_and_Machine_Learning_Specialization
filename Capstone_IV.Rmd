---
title: "Data Science Capstone"
subtitle: "Sentence Fragments and NLP II"
author: "Rohan Lewis"
date: "2020.12.13"
output:
  html_document :
    fig_height : 5
    fig_width : 8
    highlight : espresso
  
---

* * *

# I.  Background

I am now using the lines from all three documents to predict the next word for a quiz.

For each string:

<ol>
  <li>It is first sliced to the last (right most) 7 words.</li>
  <li>The new string is compared to all lines from the blogs, news, and tweets.</li>
  <li>If there are matches, the next word(s) are saved and output as a frequency table.</li>
  <li>Whether or not there were matches, the left most word is sliced off the string and the steps are repeated.</li>
  <li>At most, the top ten words will be output in a frequency table.</li>
  <li>At most, five frequency tables will be output per initial string.</li>
  <li>If at least two frequency tables have been output, the algorithm will break if only one word is left in the initial string.  Two of the initial strings end with "the" and "a" and was taking 8+ hours on creating the frequency table on that segment alone.</li>
</ol>

This data will be eventually used for predicting the next word in a random statement.

See the Appendix for code.

* * *

```{r echo = FALSE, message = FALSE}

knitr::opts_chunk$set(comment = NA)
options("scipen" = 100)
options(java.parameters = "-Xmx8g")

```

```{r echo = FALSE, message = FALSE}

library(dplyr)
library(readr)
library(RWeka)
library(stringr)
library(textclean)
library(tm)

```

```{r read, echo = FALSE, message = FALSE}
#Files are read.

blogs <- read_lines(file = "en_US.blogs.txt")

news <- read_lines(file = "en_US.news.txt")

tweets <- read_lines(file = "en_US.twitter.txt")

```

```{r functions, echo = FALSE, message = FALSE}

#Function:
#"’" is replaced with "'", contractions are expanded.
#"U.S." is replaced with "US".
#"a.m." is replaced with "am".
#"p.m." is replaced with "pm".
replacement <- function(data) {
  
  temp <- replace_contraction(gsub("’", "'", data),
                              contraction.key = lexicon::key_contractions)
  temp <- gsub("U.S.", "US", temp)
  temp <- gsub("a.m.", "am", temp)
  temp <- gsub("p.m.", "pm", temp)
  return(temp)
}



#Function returns the word immediately after a string for all lines that contain the string."
retrieve_next_words <- function(input_string) {

  #Word length of input string.
  n <- length(strsplit(input_string, " ")[[1]])
  
  #Print string and whitespace.
  cat(paste('\n\n', input_string, '...\n'))

  #Final list.
  next_words <- NULL
  
  for (bnt in bnts) {
    #Check if the string is in the line.
    if(grepl(input_string, bnt)) {
      #Find where in the line it is located.
      beginning <- str_locate(bnt, input_string)[1]
      #Start from where the string is, split by space, grab the next word.
      next_word <- strsplit(substring(bnt, beginning), " ")[[1]][n+1]
      #Get rid of non-alphanumeric.
      next_word <- str_replace_all(next_word, regex("\\W+"), "")
      #Update final list.
      next_words <- c(next_words, next_word)
    }
  }
  return(next_words)
}



possibilities <- function(q_string){
  
  #Cleanup.
  q_string <- replacement(q_string)
  #Word length of input string.
  temp_str <- str_split(q_string, " ")[[1]]
  n <- length(temp_str)
  
  #Start with last 7 words.
  if (n > 7) {
    q_string <- paste(temp_str[(n-6):n], collapse = ' ')    
  }

  tables_displayed <- 0
  while (nchar(q_string) > 0) {

    #Get next words from blogs, news, and tweets.
    q_words <- retrieve_next_words(q_string)
    
    #If there is at least one word...
    if (length(q_words > 0)) {
      
      #Update table count.
      tables_displayed <- tables_displayed + 1
      
      #Return at most 10 entries of the frequency table.

      df_freq <- df_pred_creator(q_words)
      
      if (dim(df_freq)[1] > 10){
        print.data.frame(df_freq[1:10,])
      } else {
        print.data.frame(df_freq)
      }
    }
    
    #Whether it worked or not, try again with a shortened string.
    #Shorten string by removing left most word.
    q_string <- substring(q_string, str_locate(q_string, " ")[1]+1)
    
    #Update word count.
    if (is.na(q_string)) {
      break
    } else {
      temp_str <- str_split(q_string, " ")[[1]]
      n <- length(temp_str)
      
      #If there are at least two tables and only one word left, break.
      if ((tables_displayed > 1) & (n == 1)) {
        break
      }
    }
    
    if (tables_displayed == 5) {
      break
    } 
  }
  
  #All string lengths failed to match.
  if (tables_displayed == 0) {
    return("NO MATCHES")
  }
}



#This function will create a Frequency dataframe from next_words.
df_pred_creator <- function(next_words) {

  #Convert sorted table to dataframe.
  df <- as.data.frame(sort(table(next_words), decreasing = T))
  
  #If there is only one column, change to two columns from index and single column.
  if (length(df) == 1) {
    
    df <- cbind(newColName = rownames(df), df)
    rownames(df) <- 1:nrow(df)
  }
  
  #Change Column Names.
  df <- df %>%
    `colnames<-`(c("Possible Next Word", "Frequency"))
  
  return(df)
}

print("SETUP COMPLETE")

```

* * *

# II. Predictions

```{r predictions, echo = FALSE, message = FALSE}

blogs <- replacement(blogs)

news <- replacement(news)

tweets <- replacement(tweets)

#List of all blogs, news, and tweets.
bnts <- c(blogs, news, tweets)

print("REPLACEMENT COMPLETE")

```

## 1. "When you breathe, I want to be the air for you. I'll be there for you, I'd live and I'd..."

```{r q1, echo = FALSE, message = FALSE}

q1_string <- "When you breathe, I want to be the air for you. I'll be there for you, I'd live and I'd"

possibilities(q1_string)

```

## 2. "Guy at my table's wife got up to go to the bathroom and I asked about dessert and he started telling me about his..."

```{r q2, echo = FALSE, message = FALSE}

q2_string <- "Guy at my table's wife got up to go to the bathroom and I asked about dessert and he started telling me about his"

possibilities(q2_string)

```

## 3. "I'd give anything to see arctic monkeys this..."

```{r q3, echo = FALSE, message = FALSE}

q3_string <- "I'd give anything to see arctic monkeys this"

possibilities(q3_string)

```

## 4. "Talking to your mom has the same effect as a hug and helps reduce your..."

```{r q4, echo = FALSE, message = FALSE}

q4_string <- "Talking to your mom has the same effect as a hug and helps reduce your"

possibilities(q4_string)

```

## 5. "When you were in Holland you were like 1 inch away from me but you hadn't time to take a..."

```{r q5, echo = FALSE, message = FALSE}

q5_string <- "When you were in Holland you were like 1 inch away from me but you hadn't time to take a"

possibilities(q5_string)

```

## 6. "I'd just like all of these questions answered, a presentation of evidence, and a jury to settle the..."

```{r q6, echo = FALSE, message = FALSE}

q6_string <- "I'd just like all of these questions answered, a presentation of evidence, and a jury to settle the"

possibilities(q6_string)

```

## 7. "I can't deal with unsymetrical things. I can't even hold an uneven number of bags of groceries in each..."

```{r q7, echo = FALSE, message = FALSE}

q7_string <- "I can't deal with unsymetrical things. I can't even hold an uneven number of bags of groceries in each"

possibilities(q7_string)

```

## 8. "Every inch of you is perfect from the bottom to the..."

```{r q8, echo = FALSE, message = FALSE}

q8_string <- "Every inch of you is perfect from the bottom to the"

possibilities(q8_string)

```

## 9. "I’m thankful my childhood was filled with imagination and bruises from playing..."

```{r q9, echo = FALSE, message = FALSE}

q9_string <- "I’m thankful my childhood was filled with imagination and bruises from playing"

possibilities(q9_string)

```

## 10. "I like how the same people are in almost all of Adam Sandler's..."

```{r q10, echo = FALSE, message = FALSE}

q10_string <- "I like how the same people are in almost all of Adam Sandler's"

possibilities(q10_string)

```

# III. Summary

For the ten inputs and corpus of blogs, news, and tweets:

<ol>
  <li>2. matched for seven words.</li>
  <li>7. and 8. matched for five words</li>
  <li>1. and 5. matched for four words.</li>
  <li>6. matched for three words.</li>
  <li>4., 9., and 10. matched for two words.</li>
  <li>3. matched for only one word.</li>
</ol>

Accurate prediction is extremely complex, and could be based off a reference word much earlier in the statement

Also, proper nouns like "arctic monkeys" in 3. and Adam Sandler" in 10 are extremely specific and rare to match accurately.

# Appendix

* * *

## Setup

```{r eval = FALSE}

knitr::opts_chunk$set(comment = NA)
options("scipen" = 100)
options(java.parameters = "-Xmx8g")

```

### Packages

```{r eval = FALSE}

library(dplyr)
library(readr)
library(RWeka)
library(stringr)
library(textclean)
library(tm)

```

### Read Files

```{r eval = FALSE}

#Files are read.

blogs <- read_lines(file = "en_US.blogs.txt")

news <- read_lines(file = "en_US.news.txt")

tweets <- read_lines(file = "en_US.twitter.txt")

```

### Helper Functions

```{r eval = FALSE}

#Function:
#"’" is replaced with "'", contractions are expanded.
#"U.S." is replaced with "US".
#"a.m." is replaced with "am".
#"p.m." is replaced with "pm".
replacement <- function(data) {
  
  temp <- replace_contraction(gsub("’", "'", data),
                              contraction.key = lexicon::key_contractions)
  temp <- gsub("U.S.", "US", temp)
  temp <- gsub("a.m.", "am", temp)
  temp <- gsub("p.m.", "pm", temp)
  return(temp)
}



#Function returns the word immediately after a string for all lines that contain the string."
retrieve_next_words <- function(input_string) {

  #Word length of input string.
  n <- length(strsplit(input_string, " ")[[1]])
  
  #Print string and whitespace.
  cat(paste('\n\n', input_string, '...\n'))

  #Final list.
  next_words <- NULL
  
  for (bnt in bnts) {
    #Check if the string is in the line.
    if(grepl(input_string, bnt)) {
      #Find where in the line it is located.
      beginning <- str_locate(bnt, input_string)[1]
      #Start from where the string is, split by space, grab the next word.
      next_word <- strsplit(substring(bnt, beginning), " ")[[1]][n+1]
      #Get rid of non-alphanumeric.
      next_word <- str_replace_all(next_word, regex("\\W+"), "")
      #Update final list.
      next_words <- c(next_words, next_word)
    }
  }
  return(next_words)
}



possibilities <- function(q_string){
  
  #Cleanup.
  q_string <- replacement(q_string)
  #Word length of input string.
  temp_str <- str_split(q_string, " ")[[1]]
  n <- length(temp_str)
  
  #Start with last 7 words.
  if (n > 7) {
    q_string <- paste(temp_str[(n-6):n], collapse = ' ')    
  }

  tables_displayed <- 0
  while (nchar(q_string) > 0) {

    #Get next words from blogs, news, and tweets.
    q_words <- retrieve_next_words(q_string)
    
    #If there is at least one word...
    if (length(q_words > 0)) {
      
      #Update table count.
      tables_displayed <- tables_displayed + 1
      
      #Return at most 10 entries of the frequency table.

      df_freq <- df_pred_creator(q_words)
      
      if (dim(df_freq)[1] > 10){
        print.data.frame(df_freq[1:10,])
      } else {
        print.data.frame(df_freq)
      }
    }
    
    #Whether it worked or not, try again with a shortened string.
    #Shorten string by removing left most word.
    q_string <- substring(q_string, str_locate(q_string, " ")[1]+1)
    
    #Update word count.
    if (is.na(q_string)) {
      break
    } else {
      temp_str <- str_split(q_string, " ")[[1]]
      n <- length(temp_str)
      
      #If there are at least two tables and only one word left, break.
      if ((tables_displayed > 1) & (n == 1)) {
        break
      }
    }
    
    if (tables_displayed == 5) {
      break
    } 
  }
  
  #All string lengths failed to match.
  if (tables_displayed == 0) {
    return("NO MATCHES")
  }
}



#This function will create a Frequency dataframe from next_words.
df_pred_creator <- function(next_words) {

  #Convert sorted table to dataframe.
  df <- as.data.frame(sort(table(next_words), decreasing = T))
  
  #If there is only one column, change to two columns from index and single column.
  if (length(df) == 1) {
    
    df <- cbind(newColName = rownames(df), df)
    rownames(df) <- 1:nrow(df)
  }
  
  #Change Column Names.
  df <- df %>%
    `colnames<-`(c("Possible Next Word", "Frequency"))
  
  return(df)
}

print("SETUP COMPLETE")

```

# II. Predictions

```{r eval =  FALSE}

blogs <- replacement(blogs)

news <- replacement(news)

tweets <- replacement(tweets)

bnts <- c(blogs, news, tweets)

print("REPLACEMENT COMPLETE")

```

### 1.

```{r eval = FALSE}

q1_string <- "When you breathe, I want to be the air for you. I'll be there for you, I'd live and I'd"

possibilities(q1_string)

```

### 2.

```{r eval = FALSE}

q2_string <- "Guy at my table's wife got up to go to the bathroom and I asked about dessert and he started telling me about his"

possibilities(q2_string)

```

### 3.

```{r eval = FALSE}

q3_string <- "I'd give anything to see arctic monkeys this"

possibilities(q3_string)

```

### 4.

```{r eval = FALSE}

q4_string <- "Talking to your mom has the same effect as a hug and helps reduce your"

possibilities(q4_string)

```

### 5.

```{r eval = FALSE}

q5_string <- "When you were in Holland you were like 1 inch away from me but you hadn't time to take a"

possibilities(q5_string)

```

### 6.

```{r eval = FALSE}

q6_string <- "I'd just like all of these questions answered, a presentation of evidence, and a jury to settle the"

possibilities(q6_string)

```

### 7. 

```{r eval = FALSE}

q7_string <- "I can't deal with unsymetrical things. I can't even hold an uneven number of bags of groceries in each"

possibilities(q7_string)

```

### 8.

```{r eval = FALSE}

q8_string <- "Every inch of you is perfect from the bottom to the"

possibilities(q8_string)

```

### 9.

```{r eval = FALSE}

q9_string <- "I’m thankful my childhood was filled with imagination and bruises from playing"

possibilities(q9_string)

```

### 10.

```{r eval = FALSE}

q10_string <- "I like how the same people are in almost all of Adam Sandler's"

possibilities(q10_string)

```